{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9c221-6cb2-4708-8654-02d0721e19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from conv_sparse_model import ConvSparseLayer\n",
    "\n",
    "from train_conv_sparse_model import load_mnist_data\n",
    "from train_conv_sparse_model import plot_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5c570-f1c6-497f-8b24-9daec0580ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == \"cpu\":\n",
    "    batch_size = 8\n",
    "else:\n",
    "    batch_size = 64\n",
    "\n",
    "train_loader = load_mnist_data(batch_size)\n",
    "example_data, example_targets = next(iter(train_loader))\n",
    "example_data = example_data.to(device)\n",
    "\n",
    "sparse_layer = ConvSparseLayer(in_channels=1,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=8,\n",
    "                               stride=1,\n",
    "                               padding=0,\n",
    "                               lam=0.05, \n",
    "                               activation_lr=1e-4,\n",
    "                               max_activation_iter=1000\n",
    "                               )\n",
    "sparse_layer.to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "filter_optimizer = torch.optim.Adam(sparse_layer.parameters(),\n",
    "                                   lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94497fb5-8d35-4d9f-809a-d8cc0fd606c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"mnist_out/sparse_conv3d_model-best.pt\")\n",
    "sparse_layer.load_state_dict(checkpoint['model_state_dict'])\n",
    "filter_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd7207-331f-4280-8edb-83b6e809a92f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    for local_batch, local_labels in train_loader:\n",
    "        local_batch = local_batch.to(device)\n",
    "        local_labels = local_labels.to(device)\n",
    "        activations = sparse_layer(local_batch[:, :, :, :])\n",
    "        loss = sparse_layer.loss(local_batch[:, :, :, :], activations)\n",
    "        print('loss={}'.format(loss))\n",
    "\n",
    "        filter_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        filter_optimizer.step()\n",
    "        sparse_layer.normalize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867076c7-1ccb-461b-8928-c43aa4283bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_init = torch.zeros([batch_size, sparse_layer.out_channels] +\n",
    "                    sparse_layer.get_output_shape(example_data))\n",
    "\n",
    "activations, _ = sparse_layer(example_data, u_init)\n",
    "reconstructions = sparse_layer.reconstructions(\n",
    "    activations).cpu().detach().numpy()\n",
    "\n",
    "print(\"SHAPES\")\n",
    "print(example_data.shape)\n",
    "print(example_data.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "img_to_show = 3\n",
    "for i in range(img_to_show):\n",
    "    # original\n",
    "    plt.subplot(img_to_show, 2, i*2 + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i, 0, :, :].cpu().detach().numpy(), cmap='gray',\n",
    "               interpolation='none')\n",
    "    plt.title(\"Original Image\\nGround Truth: {}\".format(\n",
    "        example_targets[0]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # reconstruction\n",
    "    plt.subplot(img_to_show, 2, i*2 + 2)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(reconstructions[i, 0, :, :], cmap='gray',\n",
    "               interpolation='none')\n",
    "    plt.title(\"Reconstruction\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde16295-2195-488a-b217-155e9422ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot_filters(sparse_layer.filters.cpu().detach())\n",
    "plt.savefig('mnist_out/filters.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9961da-dfff-43e6-9fc8-041952bc2add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ddd5bf-7615-45a2-bd9c-9827e7c2b813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pocus_project)",
   "language": "python",
   "name": "darryl_pocus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
